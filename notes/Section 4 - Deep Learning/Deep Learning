Deep Neural Network
1. Perceptron vs. Logistic regression (Gradient Descent)
2. Neural Networks
3. Cloud Computing
4. Deep Neural Networks

Deep learning Intro:
  At the heart of Deep learning is Neural Networks
  Neural Network in nutshel is drawing the boundary (straight line or curve line)

Classification Problems:
  1. Same old concepts like before. In a nutshell, we classify points on a plane by identifying a line that best
     separates the two classes (or three), but lets start with 2 first. So may be   is a line that
     separates the data on a 2-dimensional plane with x1 as horizontal and x2 as vertical axis.

     2x1 + 2x2 -18 = 0 means the point is on the line.
     2x1 + 2x2 -18 > 0 means the point is above the line
     2x1 + 2x2 -18 < 0 means the points below the line.

     Instead of three case, we can combine th first two togther.
     2x1 + 2x2 -18 >= 0 : means the point is there in that class (for example student was enrolled)
     2x1 + 2x2 -18 < 0 would me the point is not in that class (for example student was not enrolled)

     Generally speaking

     In vector form, an equation Wx + b where
     W = [w1, w2, ... wn]
     x = [x1, x2, ... xn]
     b is called the bias.

  2. Perceptron Notation:

     The above basically is a perceptron which works on a 'step function'. The step function basically says if the function
     return >= 0 output yes, if the function says < 0 out put 0.

     Pictoriaally (which I cannot draw here).

                        . .              . .       / yes -> 1
        x1 --w1---->  .     .          .     .    /
        x2 --w2--->  .        .       .        . /
        x3 --w3--->  .  Sum   .  -->  .  >=0?  . \
        x4 --w4--->   .      .         .      .    \
        b  ------->    . . .             . . .       \ no -> 0

					  node         Step function

     Representing logical operators as perceptrons:
       AND:

       OR:

       XOR:

       The elusive ?

     Perceptron Trick:
       Points misqualified would like the line come closer to them (or better, cross over them) so that the misqualified
       point ends up in the right region.

       Let
       3x1 + 4x2 - 10 = 0
       be the line.

       The points over it have x1, x2 so that
       3x1 + 4x2 - 10 > 0 --> blue area
       and those under it have x1, x2 so that
       3x1 + 4x2 - 10 < 0 --> red area.

       Suppose there is a red point in the blue area and it is (4, 5). This point wants the line come closer to it or
       move over it so the point ends up in the red area instead of blue. For this, (to move line closer to the point)
       subtract points (4, 5) (and consider 1 for bias) from the components of the line above.

       3    4   -10
       4    5   -1
       ----------------
       -1   -1  -11

       This will bring the line closer to the point (or may even cross it over). However, we generally take smaller steps
       controlled through a "learning rate" parameter - lets say 0.1. We multiply this factor with the points of the line
       before subtracting ... so the computation will become

           3        4       -10
       4*0.1    5*0.1   -1*0.1
       -----------------------
       2.5      3.5     -10.1

        New line will therefore be

       2.5x1 + 3.5x2 - 10.1 = 0

       That's it. That's the Perceptron trick. Similarly, if a blue point was in red area, we would ADD (instead of subtracing)
       the line points from the coeffients of the equation.

     The Algorithm Psuedocode
       So obviously line wont do in most cases. We have to use a curve.
       How do we get that curve? We can use error functions to help us with that.
       Gradient Descent helps us reduce the error as we already know. Our error functions have to be continous and diffrentiable.
       Discrete vs. Continous:
         Sigmoid function: Instead of saying student go accepted or rejected, we say the probability of acceptance of this student
         is this much and of not being accepted is this much.
         So instead of a STEP function, we use Sigmoid function. Formula is

         sigmoid = 1/(1+e to the power -x)
       So for a function
       4x1 + 5x2 - 9 = 0
       What is the value of sigmoid for (1,1)?

        import math
        def sigmoid(x):
            return 1 / (1+math.exp(-x))

        def step(x1, x2):
            return 4*x1 + 5*x2 - 9

       Ans: --> sigmoid(step(1, 1)
       Or detailed.
        (1, 1) --> 0 --> sigmod(0) = 0.5
        (2, 4) --> 16 + 20 - 9 --> 19 --> sigmoid(27) --> 0.99
        (5, -5) --> 20 - 25 - 9 --> -14 --> sigmoid(-14) --> 0.00000008
        (-4, 5) --> -20 + 25 -9 --> -4 --> sigmoid(-4) --> 0.5

       Multiclass Problems:
         1. yes/no is not going to help with cases where classes more than 2. We need more answers than yes/no.
         2. with multiclass problems, we have chance of probabilty spread across 3 or more classes.
         3. These probabilities should still add up to one.
         4. So for each class, we get some sort of scoring. These scores have to be converted to probabilities.

         The formula for that is

         Given scores, z1, z2, ... zn, probability that the target is in class i is

         p(class i) = math.exp(zi) /(math.exp(z1) + math.exp(z1) ... math.exp(zn))
         That's how we turn scores into probabilities. This is called softmax function.

         So when we have two classes, we use sigmoid, when we have more classes, we use softmax function.
         TODO: Quiz
         16. Softmax - make sure you do the quiz.

         One-hot encoding - assigning
           1. Numerical values to the string outputs.
           2. Outputs that have string meanings, we convert them to numerical.
                I got a gift -- 1
                I didn't get a gift -- 0.

              But what about multi-class problems?

              Animal is Beaver
              Animal is Cat
              Animal is dog

              ?

              May be use 0, 1, and 2 for the classes? But we cannot do that because that will create dependencies on the
              classes which we do not want.

              So instead we use multiple variables for each case with values still as 0 and 1 but each one now having their own column

             ---------------------------------------------
              Animal       Duck?       Beaver      Walrus
             ---------------------------------------------
              Duck          1           0             0
              Beaver        0           1             0
              Duck          1           0             0
              Walrus        0           0             1
              Beaver        0           1             0
             ---------------------------------------------
             One-hot encoding multi-class inputs
         Maximum Likelihood:
           Maximizing the probability that a point is falling in the correct category.

		Suppose X are apples and 0 are Oranges.

		Which one of the two models separting Xs from Zeros is better?

           +-------------------------+		+-------------------------+
           |             01  .       |      |       .      01         |
           |            .            |      |         .               |
           |   x1    .               |      |   x1     .              |
           |    .              02    |      |           .       02    |
           | .     x2                |      |       x2   .            |
           +-------------------------+      +-------------------------+
                  A). Bad Model						B). Good Model

        But from probability perspective, lets see how one is worse than the other:

        probability (all) should be maximized ... probability of the whole arrangement that we are interested in here.
        p(all) is the probability that the point is what it says it is based on the model. (product of all these
        probabilities). You wil get higher value for B than A. So that's why B is a better model (not just pictorially,
        but we just saw w.r.t probability as well.)

        But products are expensive - we must do additions instead. So we must convert products into sums. Sounds like
        we are talking about logs here (logs convert products to sums).

        Softmax function:

          So for the formula mentioned above,

          p(class i) = math.exp(zi) /(math.exp(z1) + math.exp(z1) ... math.exp(zn))

          For a given list of numbers as input, we will have their entropies as follows using the softmax function

          import numpy as np

          # Write a function that takes as input a list of numbers, and returns
          # the list of values given by the softmax function.
          def softmax(L):
              expL = np.exp(L)
              sumExpL = sum(expL)
              result = []
              for i in expL:
                  result.append(i*1.0/sumExpL)
              return result

        Cross Entropy:
          Given a set of events and probabilties, what is
          Sum of the Negative log of the probabilities.
          Minimize Cross Entropy instead of increasing the probability.
          The more the entropy of an event + probability combination, the worse the model and vice versa.

          program:
          def entropy(Y, P):
            Y = np.float_(Y)
            P = np.float_(P)
            return -np.sum(Y * np.log(P) + (1 - Y) * np.log(1 - P))

         Gradient Descent:
           Mathematically, Gradient Descent will look like a three dimensional with axis (w1, w2 and error E) while our
           mountaineer walks on a mountain surface in this 3-dimentional space - the height of the mountains shows signifies
           error (E). So our gradient descent is the derivate of error with respective to w1 and w2. The higher this value,
           the more the error, so we take the negative of this to reduce the error.

           So now, we have our y_cap (or prediction) we saw
             y_cap = sigmoid(Wx + b) <------------- was bad prediction, lets minimize the error using gradient descent
             y_cap = sigmoid(w1x1 + w2x2 + ... wnxn +b)
             grad_descent = (dE/dw1, dE/dw2, ... dE/dwn + dE/db)

             but no big steps - so learning rate is important

             alpha = 0.1

             So

             new_weight_w1 w' will become

             wi' = wi - alpha * dE/dwi (i.e, older weight minus the error with respect to that weight is new weight)
             b' = b - alpha * dE/db (same for our new bias)

             Therefore,

             y_cap = sigmoid(W'x + b') <------------- Should take our mountaineer to a step down - prediction with less
                                                      error.

           Paper work:
             Do derivate of sigmoid function on a paper you should get something interesting and nice.
             Given,
             sigmoid (x) = 1 (1 + e to the power -x)
             We have its derivative as follows - do on paper to prove.
             sigmoid'(x) = sigmoid(x) * 1 / (1 - sigmoid(x))

             ... may be missing some details here - but look at the calculations of the derivates in the paper notebook.
             which also doesn't cover all - but will give you an idea.
             So, in summary
             dE/dwi = (y^ - y).x
             dE/dwb = (y^ - y)

         Algorithm:
           So we have all the tools for the gradient descent now we write the algorithm.
           ... write algo here ..

           1. Start with random weights
              w1, w2, ... wn

           2. For each point x1, x2, ... xn
              2.1 For i = 1 .. n
                  2.1.1. Update wi' <-- wi - alpha * dE/dwi
                  2.1.2. Update b' <-- b - alpha * dE/b
                         but we already know that
                         dE/dwi = (y^ - y).x
                         dE/dwb = (y^ - y)

                         so
                         wi' <-- wi - alpha * (y^ - y).x
                         b' <-- b - alpha * (y^ - y)
                  2.1.3. Repeat until he error is small.

         TODO: 27 Implement Graient Descent by cloning form the

         Perceptron Algorithm vs Gradient Descent (or Logistic regression).
         1. Both help us find out the line that splits up the data into two lines.
         2. Perceptron outputs 1 and 0, Logistic regression outputs probabilities.
         3. But now what if a line cannot classify the data? This is the subject of Deep Neural Network

           # of times we move the line to fit the model is called epox - will learn later.
           hmm, suspiciously looking familiar - yes, thats what the Perceptron algorihtm did too.

  Deep Neural Network:
    Over impose multiple straight lines to come up with a curve. This idea is at the heart of Neural Networks.
    Calculate the prob of one point then apply the sigmoid functions.
    Also, you can assign weights to each point.

    One constant times another + another constant times another model --> probability

    Take Away:
      So the idea is to assign weights to the outputs of each NN and add them together but before adding, figure out
      what weights each of them should carry. A linear combination of the outputs of two neural networks.

      Whenever you see a neural network constructed from multiple other networks, think of the "non linear"
      boundaries defined from the linear combination of the two linear neural networks. Powerful.

    Way more complicated:
      Input layer: Inputs (like x1, x2)
      Hidden Layer: Set of all neural networks
      Output layer: All linear networks combined in this layer to get non-linear output.

      Many architectures (really cool - pictorially, it would have been great though):
        a. If Hidden layer has 3 sets instead of two, we are talking about a triange instead of a curve.
        b. If inputs can be more than 2 - meaning no more living in 2-dimensional, In this case, the hidden layer
           shall have planes instead of lines, and the output layer shall have a 3-dimensional curved plane instead of
           a straight plane.
        c. What if the output layer has more modes than two? Now we are talking about multi class classification problem
           The output layer will not have just one but 3 (for example) curved layers - one for each class (Cat, Dog, Bird exp).

        d. (Cooler!!) What if we have more than one 'hidden layers' - So recall, the first layer had linear models,
           them combined gave us a non-linear model like curves. Now if these curves also are combined together (hidden layers
           more than 1), we will get even more complex curves than a simple curve (like an S share curve instead of a C shape curve - isn't it cool?0

           This architecture is called Deep Neural Network. Name is cool too.

           In real world applications like self-driving cars of game-playing agents, there are multiple layers like mentioned in the last point above
           Many linear neural networks combined to come up with a very curvy and complex classification ... more complex than an S-shaped curve for example.

        Ex: One (good) architechure that addresses the problem of identify the 26 upper case letters in English alphabet would require you to add 26 nodes into the
        output layer. Other (bad) architecures may also work - but they may be overkills - like having 26 separate NN each telling us if a letter was , A, B, C etc.

      How to train deep neural networks:
        Training means coming up with weights on the edges.
        FeedForward: --
        backpropogation: Adjust weights when a point is misqualified.
        Generally speaking,
           Descent from Mount Averest:
             a. Standing at a point, predict y^.
             b. Calculate the error w.r.t W --> E(W),
             c. then find out the (negative of) the gradient descent of the error (-D(E))
                to find out what direction to go until error is negligible.

           Same older formulae:
             y^ = sigmoid (Wx + b)
             E(W) = -1/m Summation {i --> 1 .. m (yi.ln(y^) + (1-yi)ln(1-y^))}
             D(E) = (dE/dw1, ... dE/dwn, dE/db) <-- partial derivates of the error w.r.t weights (and the bias).

           In multilayer perceptron, it translates to
        backprogogation:
          - do feedforward operation
          -    


