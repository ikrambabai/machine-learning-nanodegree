Deep Neural Network
1. Perceptron vs. Logistic regression (Gradient Descent)
2. Neural Networks
3. Cloud Computing
4. Deep Neural Networks

Deep learning Intro:
  At the heart of Deep learning is Neural Networks
  Neural Network in nutshel is drawing the boundary (straight line or curve line)

Classification Problems:
  1. Same old concepts like before. In a nutshell, we classify points on a plane by identifying a line that best
     separates the two classes (or three), but lets start with 2 first. So may be   is a line that
     separates the data on a 2-dimensional plane with x1 as horizontal and x2 as vertical axis.

     2x1 + 2x2 -18 = 0 means the point is on the line.
     2x1 + 2x2 -18 > 0 means the point is above the line
     2x1 + 2x2 -18 < 0 means the points below the line.

     Instead of three case, we can combine th first two togther.
     2x1 + 2x2 -18 >= 0 : means the point is there in that class (for example student was enrolled)
     2x1 + 2x2 -18 < 0 would me the point is not in that class (for example student was not enrolled)

     Generally speaking

     In vector form, an equation Wx + b where
     W = [w1, w2, ... wn]
     x = [x1, x2, ... xn]
     b is called the bias.

  2. Perceptron Notation:

     The above basically is a perceptron which works on a 'step function'. The step function basically says if the function
     return >= 0 output yes, if the function says < 0 out put 0.

     Pictoriaally (which I cannot draw here).

                        . .              . .       / yes -> 1
        x1 --w1---->  .     .          .     .    /
        x2 --w2--->  .        .       .        . /
        x3 --w3--->  .  Sum   .  -->  .  >=0?  . \
        x4 --w4--->   .      .         .      .    \
        b  ------->    . . .             . . .       \ no -> 0

					  node         Step function

     Representing logical operators as perceptrons:
       AND:

       OR:

       XOR:

       The elusive ?

     Perceptron Trick:
       Points misqualified would like the line come closer to them (or better, cross over them) so that the misqualified
       point ends up in the right region.

       Let
       3x1 + 4x2 - 10 = 0
       be the line.

       The points over it have x1, x2 so that
       3x1 + 4x2 - 10 > 0 --> blue area
       and those under it have x1, x2 so that
       3x1 + 4x2 - 10 < 0 --> red area.

       Suppose there is a red point in the blue area and it is (4, 5). This point wants the line come closer to it or
       move over it so the point ends up in the red area instead of blue. For this, (to move line closer to the point)
       subtract points (4, 5) (and consider 1 for bias) from the components of the line above.

       3    4   -10
       4    5   -1
       ----------------
       -1   -1  -11

       This will bring the line closer to the point (or may even cross it over). However, we generally take smaller steps
       controlled through a "learning rate" parameter - lets say 0.1. We multiply this factor with the points of the line
       before subtracting ... so the computation will become

           3        4       -10
       4*0.1    5*0.1   -1*0.1
       -----------------------
       2.5      3.5     -10.1

        New line will therefore be

       2.5x1 + 3.5x2 - 10.1 = 0

       That's it. That's the Perceptron trick. Similarly, if a blue point was in red area, we would ADD (instead of subtracing)
       the line points from the coeffients of the equation.

     The Algorithm Psuedocode
       So obviously line wont do in most cases. We have to use a curve.
       How do we get that curve? We can use error functions to help us with that.
       Gradient Descent helps us reduce the error as we already know. Our error functions have to be continous and diffrentiable.
       Discrete vs. Continous:
         Sigmoid function: Instead of saying student go accepted or rejected, we say the probability of acceptance of this student
         is this much and of not being accepted is this much.
         So instead of a STEP function, we use Sigmoid function. Formula is

         sigmoid = 1/(1+e to the power -x)
       So for a function
       4x1 + 5x2 - 9 = 0
       What is the value of sigmoid for (1,1)?

        import math
        def sigmoid(x):
            return 1 / (1+math.exp(-x))

        def step(x1, x2):
            return 4*x1 + 5*x2 - 9

       Ans: --> sigmoid(step(1, 1)
       Or detailed.
        (1, 1) --> 0 --> sigmod(0) = 0.5
        (2, 4) --> 16 + 20 - 9 --> 19 --> sigmoid(27) --> 0.99
        (5, -5) --> 20 - 25 - 9 --> -14 --> sigmoid(-14) --> 0.00000008
        (-4, 5) --> -20 + 25 -9 --> -4 --> sigmoid(-4) --> 0.5

       Multiclass Problems:
         1. yes/no is not going to help with cases where classes more than 2. We need more answers than yes/no.
         2. with multiclass problems, we have chance of probabilty spread across 3 or more classes.
         3. These probabilities should still add up to one.
         4. So for each class, we get some sort of scoring. These scores have to be converted to probabilities.

         The formula for that is

         Given scores, z1, z2, ... zn, probability that the target is in class i is

         p(class i) = math.exp(zi) /(math.exp(z1) + math.exp(z1) ... math.exp(zn))
         That's how we turn scores into probabilities. This is called softmax function.

         So when we have two classes, we use sigmoid, when we have more classes, we use softmax function.
         TODO: Quiz
         16. Softmax - make sure you do the quiz.

         One-hot encoding - assigning
           1. Numerical values to the string outputs.
           2. Outputs that have string meanings, we convert them to numerical.
                I got a gift -- 1
                I didn't get a gift -- 0.

              But what about multi-class problems?

              Animal is Beaver
              Animal is Cat
              Animal is dog

              ?

              May be use 0, 1, and 2 for the classes? But we cannot do that because that will create dependencies on the
              classes which we do not want.

              So instead we use multiple variables for each case with values still as 0 and 1 but each one now having their own column

             ---------------------------------------------
              Animal       Duck?       Beaver      Walrus
             ---------------------------------------------
              Duck          1           0             0
              Beaver        0           1             0
              Duck          1           0             0
              Walrus        0           0             1
              Beaver        0           1             0
             ---------------------------------------------
             One-hot encoding multi-class inputs
         Maximum Likelihood:
           Maximizing the probability that a point is falling in the correct category.

		Suppose X are apples and 0 are Oranges.

		Which one of the two models separting Xs from Zeros is better?

           +-------------------------+		+-------------------------+
           |             01  .       |      |       .      01         |
           |            .            |      |         .               |
           |   x1    .               |      |   x1     .              |
           |    .              02    |      |           .       02    |
           | .     x2                |      |       x2   .            |
           +-------------------------+      +-------------------------+
                  A). Bad Model						B). Good Model

        But from probability perspective, lets see how one is worse than the other:

        probability (all) should be maximized ... probability of the whole arrangement that we are interested in here.
        p(all) is the probability that the point is what it says it is based on the model. (product of all these
        probabilities). You wil get higher value for B than A. So that's why B is a better model (not just pictorially,
        but we just saw w.r.t probability as well.)

        But products are expensive - we must do additions instead. So we must convert products into sums. Sounds like
        we are talking about logs here (logs convert products to sums).

        Softmax function:

          So for the formula mentioned above,

          p(class i) = math.exp(zi) /(math.exp(z1) + math.exp(z1) ... math.exp(zn))

          For a given list of numbers as input, we will have their entropies as follows using the softmax function

          import numpy as np

          # Write a function that takes as input a list of numbers, and returns
          # the list of values given by the softmax function.
          def softmax(L):
              expL = np.exp(L)
              sumExpL = sum(expL)
              result = []
              for i in expL:
                  result.append(i*1.0/sumExpL)
              return result

        Cross Entropy:
          Given a set of events and probabilties, what is
          Sum of the Negative log of the probabilities.
          Minimize Cross Entropy instead of increasing the probability.
          The more the entropy of an event + probability combination, the worse the model and vice versa.

          program:
          def entropy(Y, P):
            Y = np.float_(Y)
            P = np.float_(P)
            return -np.sum(Y * np.log(P) + (1 - Y) * np.log(1 - P))

         Gradient Descent:
           Mathematically, Gradient Descent will look like a three dimensional with axis (w1, w2 and error E) while our
           mountaineer walks on a mountain surface in this 3-dimentional space - the height of the mountains shows signifies
           error (E). So our gradient descent is the derivate of error with respective to w1 and w2. The higher this value,
           the more the error, so we take the negative of this to reduce the error.

           So now, we have our y_cap (or prediction) we saw
             y_cap = sigmoid(Wx + b) <------------- was bad prediction, lets minimize the error using gradient descent
             y_cap = sigmoid(w1x1 + w2x2 + ... wnxn +b)
             grad_descent = (dE/dw1, dE/dw2, ... dE/dwn + dE/db)

             but no big steps - so learning rate is important

             alpha = 0.1

             So

             new_weight_w1 w' will become

             wi' = wi - alpha * dE/dwi (i.e, older weight minus the error with respect to that weight is new weight)
             b' = b - alpha * dE/db (same for our new bias)

             Therefore,

             y_cap = sigmoid(W'x + b') <------------- Should take our mountaineer to a step down - prediction with less
                                                      error.

           Paper work:
             Do derivate of sigmoid function on a paper you should get something interesting and nice.
             Given,
             sigmoid (x) = 1 (1 + e to the power -x)
             We have its derivative as follows - do on paper to prove.
             sigmoid'(x) = sigmoid(x) * 1 / (1 - sigmoid(x))

             ... may be missing some details here - but look at the calculations of the derivates in the paper notebook.
             which also doesn't cover all - but will give you an idea.
             So, in summary
             dE/dwi = (y^ - y).x
             dE/dwb = (y^ - y)

         Algorithm:
           So we have all the tools for the gradient descent now we write the algorithm.
           ... write algo here ..

           1. Start with random weights
              w1, w2, ... wn

           2. For each point x1, x2, ... xn
              2.1 For i = 1 .. n
                  2.1.1. Update wi' <-- wi - alpha * dE/dwi
                  2.1.2. Update b' <-- b - alpha * dE/b
                         but we already know that
                         dE/dwi = (y^ - y).x
                         dE/dwb = (y^ - y)

                         so
                         wi' <-- wi - alpha * (y^ - y).x
                         b' <-- b - alpha * (y^ - y)
                  2.1.3. Repeat until he error is small.

         TODO: 27 Implement Graient Descent by cloning form the

         Perceptron Algorithm vs Gradient Descent (or Logistic regression).
         1. Both help us find out the line that splits up the data into two lines.
         2. Perceptron outputs 1 and 0, Logistic regression outputs probabilities.
         3. But now what if a line cannot classify the data? This is the subject of Deep Neural Network

           # of times we move the line to fit the model is called epox - will learn later.
           hmm, suspiciously looking familiar - yes, thats what the Perceptron algorihtm did too.

  Deep Neural Network:
    Over impose multiple straight lines to come up with a curve. This idea is at the heart of Neural Networks.
    Calculate the prob of one point then apply the sigmoid functions.
    Also, you can assign weights to each point.

    One constant times another + another constant times another model --> probability

    Take Away:
      So the idea is to assign weights to the outputs of each NN and add them together but before adding, figure out
      what weights each of them should carry. A linear combination of the outputs of two neural networks.

      Whenever you see a neural network constructed from multiple other networks, think of the "non linear"
      boundaries defined from the linear combination of the two linear neural networks. Powerful.

    Way more complicated:
      Input layer: Inputs (like x1, x2)
      Hidden Layer: Set of all neural networks
      Output layer: All linear networks combined in this layer to get non-linear output.

      Many architectures (really cool - pictorially, it would have been great though):
        a. If Hidden layer has 3 sets instead of two, we are talking about a triange instead of a curve.
        b. If inputs can be more than 2 - meaning no more living in 2-dimensional, In this case, the hidden layer
           shall have planes instead of lines, and the output layer shall have a 3-dimensional curved plane instead of
           a straight plane.
        c. What if the output layer has more modes than two? Now we are talking about multi class classification problem
           The output layer will not have just one but 3 (for example) curved layers - one for each class (Cat, Dog, Bird exp).

        d. (Cooler!!) What if we have more than one 'hidden layers' - So recall, the first layer had linear models,
           them combined gave us a non-linear model like curves. Now if these curves also are combined together (hidden layers
           more than 1), we will get even more complex curves than a simple curve (like an S share curve instead of a C shape curve - isn't it cool?0

           This architecture is called Deep Neural Network. Name is cool too.

           In real world applications like self-driving cars of game-playing agents, there are multiple layers like mentioned in the last point above
           Many linear neural networks combined to come up with a very curvy and complex classification ... more complex than an S-shaped curve for example.

        Ex: One (good) architechure that addresses the problem of identify the 26 upper case letters in English alphabet would require you to add 26 nodes into the
        output layer. Other (bad) architecures may also work - but they may be overkills - like having 26 separate NN each telling us if a letter was , A, B, C etc.

      How to train deep neural networks:
        Training means coming up with weights on the edges.
        FeedForward: --
        backpropogation: Adjust weights when a point is misqualified.
        Generally speaking,
           Descent from Mount Averest:
             a. Standing at a point, predict y^.
             b. Calculate the error w.r.t W --> E(W),
             c. then find out the (negative of) the gradient descent of the error (-D(E))
                to find out what direction to go until error is negligible.

           Same older formulae:
             y^ = sigmoid (Wx + b)
             E(W) = -1/m Summation {i --> 1 .. m (yi.ln(y^) + (1-yi)ln(1-y^))}
             D(E) = (dE/dw1, ... dE/dwn, dE/db) <-- partial derivates of the error w.r.t weights (and the bias).

           In multilayer perceptron, it translates to
        backprogogation:
          - do feedforward operation
          -

       Regularization
         L1 regularization
         L2 regularization
       Dropout layer:
         ??? -- the probability that any node in the NN is removed during training.
       Batch vs Stochasit Gradiant Descent
         Stochastic works on a subset of data but takes multipe steps than just one like in Gradiant Descent.
       Learning rate ... keep it low if your model cannot learn good
       Momentum
       Other Optimizer:
         SGD, Momentum, NAG, Adagrad, Adadelta, Rmsprop
       Other Activation Functions:
         RelU --> negative to zero, positives leave alone -- max(0, a)
           Relu functions solves the issue with the problem of diminishing gradients.

  Convolutional Neural Networks:
    Categorical Cross Entropy loss:
      less loss when the model says what the label says,
      More loss when the model says something other than the label says.

      Training decisions: Many decisions to make when deciding the 'architecture' of the model.
        How many layers to pick?
        How many node in each layer to pick?
        How many ephocs to pick.

      Data:
        Training Data: <-- only look at this when deciding the weights.
        Validation Data: <-- only to validate if we are going in the right direction. Therefore validation can tell us
                    how we are doing on the overfitting.

                    ^
                    |
                    |
                    | .                       x  x   x   x  validation loss
                    |  .                   x
               loss | x .               x
                    |  x  .           x
                    |    x  .      x
                    |       x   x.   .  .  . . . training loss
                    +----------|---------------------------------------->
                              100                                epochs

            Notice evidence of overfitting around epochs > 100 - we would just want to stop at the epoch
            where the validation loss elevates from the training loss.

        Test Data:

       MLP Vs. CNN:
         1.
         fully connected - on our 28x28 size db, the number of parameters went up to .5 million already.
         Imagine how MLPs will grow with other bigger / real world images. CNNs will be sparsely connected because
         we not every node in the image really has to 'see' or be responsible for ALL nodes coming in from the input
         layer. May be just the first 4x4 quadrant of a 16x16 image? This is more 'locally-connected' layer than the
         MSPs fully connected nodes.

         2.
         Accepts only vectors as input, not matrices. So an image representing 5 was basically broken into one row
         and fed to MLP - This means we went from 2D to 1D loosing very precious spatial information on where the
         data actually WAS that was fed to the MLP. CNNs know the location of the image

         Convolutional layer height and width: Size of filter
         Strides and padding: What happens to the edge where the filter may run over the end / edge of the image?
           Use or not use the padding (padding = 'valid' vs padding = 'same' - in 1, you throw away the nodes that
           couldn't get all of its nodes to contribute because it was at the edge of the image. In 2nd case, you did
           padding already to prep for such situation and DO take the those hidden nodes into consideration that would
           have been thrown otherwise.

         Pooling layers:
           Help reduce dimensionality by reducing the feature map from previous conv layer to next pooling layer.
           Conv Layer --> Pooling layer --> Conv layer --> so on.
           Help reduce the dimensionality of the filters (to avoid overfitting).
           Pooling layer types:
             Max Pooling layer: >> Take feature map as input (each resp for identifying a pattern). Reduce the size of
               the feature by half by reducing all the features to the max only. So a 2x2 section of the 4x4 feature will
               output one value - the max of the 4 - each of the 2x2 will output one max resulting in 4 numbers from the
               16 original effectively reducing the dimension by 4 times. This is done by specifying window size and stride.

             Global Average Pooling layer:
               Same as above, but now instead of max, it goes by the average of all the numbers in that section. For
               this type of pooling, we do not specify the stride or the window size - its extreme on dimensionality reduction
               because it takes the average of the whole feature map - so a 4x4 feature map of 16 value will be reduce to
               a single value - So a 3D array will be converted to a vector.





