 Gradient Descent:
   Mathematically, Gradient Descent will look like a three dimensional with axis (w1, w2 and error E) while our
   mountaineer walks on a mountain surface in this 3-dimentional space - the height of the mountains shows signifies
   error (E). So our gradient descent is the derivate of error with respective to w1 and w2. The higher this value,
   the more the error, so we take the negative of this to reduce the error.

   So now, we have our y_cap (or prediction) we saw
     y_cap = sigmoid(Wx + b) <------------- was bad prediction, lets minimize the error using gradient descent
     y_cap = sigmoid(w1x1 + w2x2 + ... wnxn +b)
     grad_descent = (dE/dw1, dE/dw2, ... dE/dwn + dE/db)

     but no big steps - so learning rate is important

     alpha = 0.1

     So

     new_weight_w1 w' will become

     wi' = wi - alpha * dE/dwi (i.e, older weight minus the error with respect to that weight is new weight)
     b' = b - alpha * dE/db (same for our new bias)

     Therefore,

     y_cap = sigmoid(W'x + b') <------------- Should take our mountaineer to a step down - prediction with less
                                              error.

   Paper work:
     Do derivate of sigmoid function on a paper you should get something interesting and nice.
     Given,
     sigmoid (x) = 1 (1 + e to the power -x)
     We have its derivative as follows - do on paper to prove.
     sigmoid'(x) = sigmoid(x) * 1 / (1 - sigmoid(x))

     ... may be missing some details here - but look at the calculations of the derivates in the paper notebook.
     which also doesn't cover all - but will give you an idea.
     So, in summary
     dE/dwi = (y^ - y).x
     dE/dwb = (y^ - y)

 Algorithm:
   So we have all the tools for the gradient descent now we write the algorithm.
   ... write algo here ..

   1. Start with random weights
      w1, w2, ... wn

   2. For each point x1, x2, ... xn
      2.1 For i = 1 .. n
          2.1.1. Update wi' <-- wi - alpha * dE/dwi
          2.1.2. Update b' <-- b - alpha * dE/b
                 but we already know that
                 dE/dwi = (y^ - y).x
                 dE/dwb = (y^ - y)

                 so
                 wi' <-- wi - alpha * (y^ - y).x
                 b' <-- b - alpha * (y^ - y)
          2.1.3. Repeat until he error is small.

 TODO: 27 Implement Graient Descent by cloning form the

 Perceptron Algorithm vs Gradient Descent (or Logistic regression).
 1. Both help us find out the line that splits up the data into two lines.
 2. Perceptron outputs 1 and 0, Logistic regression outputs probabilities.
 3. But now what if a line cannot classify the data? This is the subject of Deep Neural Network

   # of times we move the line to fit the model is called epox - will learn later.
   hmm, suspiciously looking familiar - yes, thats what the Perceptron algorihtm did too.
